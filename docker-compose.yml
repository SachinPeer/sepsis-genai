version: '3.8'

services:
  sepsis-genai:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: sepsis-genai-api
    ports:
      - "8000:8000"
    environment:
      # API Security
      - API_KEY=${API_KEY:-sepsis_api_key_2024}
      # LLM Provider Selection: "azure" or "bedrock"
      - LLM_PROVIDER=${LLM_PROVIDER:-bedrock}
      # Azure OpenAI Configuration
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_DEPLOYMENT_NAME=${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-4o}
      - AZURE_OPENAI_MODEL=${AZURE_OPENAI_MODEL:-gpt-4o}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2024-06-01}
      # AWS Bedrock Configuration (Claude 3.5 Sonnet)
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - BEDROCK_MODEL_ID=${BEDROCK_MODEL_ID:-us.anthropic.claude-3-5-sonnet-20241022-v2:0}
    volumes:
      # Mount guardrail config for hot-reload capability
      - ./genai_clinical_guardrail.json:/app/genai_clinical_guardrail.json:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
